# Welcome to Awesome AI Research

> NB: This repo is a WIP and I hope to keep refreshing and extending it as time allows

Welcome to `awesome-ai-research`, a personal collection of research papers that have piqued my interest in the expansive field of artificial intelligence, especially focusing on Large Language Models (LLMs) and their multifaceted applications.

Artificial intelligence is a dynamic field where innovation is constant. The papers included here reflect a range of work that I've found interesting - you may or may not too! :)

Here, you'll discover papers covering everything from enhancing the reasoning abilities of AI systems to innovative approaches for training and benchmarking. Each selection is driven by a personal interest and a belief in the importance of the work, rather than a comprehensive or systematic review.

I hope this collection serves as a springboard for your exploration and inspires a deeper understanding and appreciation of artificial intelligence.

## Reasoning

> This section presents papers exploring advanced reasoning capabilities of Large Language Models (LLMs). Topics include self-improvement techniques, multi-agent systems, ethical reasoning, mathematical reasoning, and approaches to enhance LLMs' ability to process and generate logically coherent and contextually relevant responses. Expect insights on enhancing code generation, debugging, and solving complex algorithmic challenges.

- General
  - 2024
    - [Reason from Fallacy: Enhancing Large Language Models’ Logical Reasoning through Logical Fallacy Understanding](https://arxiv.org/pdf/2404.04293.pdf) (04/2024)
    - [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing (AlphaLLM)](https://arxiv.org/pdf/2404.12253.pdf) (04/2024)
    - [Stream of Search (SoS): Learning to Search in Language](https://arxiv.org/pdf/2404.03683.pdf) (04/2024)
    - [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](https://arxiv.org/pdf/2404.02575.pdf) (04/2024)
    - [DON’T TRUST: VERIFY – GROUNDING LLM QUANTITATIVE REASONING WITH AUTOFORMALIZATION](https://arxiv.org/pdf/2403.18120.pdf) (03/2024)
    - [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/pdf/2403.09629.pdf) (03/2024)
    - [Self-Discover: Large Language Models Self-Compose Reasoning Structures](https://arxiv.org/pdf/2402.03620.pdf) (02/2024)
  - 2023
    - [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/pdf/2312.17080.pdf) (12/2023)
    - [Retrieval-Augmented Multi-Modal Chain-of-Thoughts Reasoning for Large Language Models](https://arxiv.org/pdf/2312.01714.pdf) (12/2023)
    - [MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING](https://arxiv.org/pdf/2309.05653.pdf) (09/2023)
    - [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models](https://arxiv.org/pdf/2309.05605.pdf) (09/2023)
    - [Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation](https://arxiv.org/abs/2311.04254) (11/2023)
    - [HINT-ENHANCED IN-CONTEXT LEARNING WAKES LARGE LANGUAGE MODELS UP FOR KNOWLEDGE-INTENSIVE TASKS](https://arxiv.org/pdf/2311.01949.pdf) (11/2023)
    - [LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers](https://arxiv.org/pdf/2310.15164.pdf) (10/2023)
    - [BRANCH-SOLVE-MERGE IMPROVES LARGE LANGUAGE MODEL EVALUATION AND GENERATION](https://arxiv.org/pdf/2310.15123.pdf) (10/2023)
    - [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/pdf/2305.10601.pdf) (05/2023)
    - [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/pdf/2305.04091.pdf) (05/2023)
    - [Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework](https://arxiv.org/pdf/2305.03268.pdf) (05/2023)
    - [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality](https://arxiv.org/pdf/2305.00050.pdf) (05/2023)
    - [Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models](https://arxiv.org/pdf/2306.06891.pdf) (06/2023)
    - [Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models](https://arxiv.org/pdf/2304.09842.pdf) (04/2023)
    - [Progressive-Hint Prompting Improves Reasoning in Large Language Models](https://arxiv.org/pdf/2304.09797.pdf) (04/2023)
- Coding
  - 2024
    - [MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue ReSolution](https://arxiv.org/pdf/2403.17927.pdf) (03/2024)
    - [Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](https://arxiv.org/pdf/2401.08500.pdf) (01/2024)
  - 2023
    - [AgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation](https://arxiv.org/pdf/2312.13010.pdf) (12/2023)
    - [INTERVENOR: Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair](https://arxiv.org/pdf/2311.09868.pdf) (11/2023)
    - [COFFEE: Boost Your Code LLMs by Fixing Bugs with Feedback](https://arxiv.org/pdf/2311.07215.pdf) (11/2023)
    - [MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning](https://arxiv.org/pdf/2311.02303.pdf) (11/2023)
    - [ClarifyGPT: Empowering LLM-based Code Generation with Intention Clarification](https://arxiv.org/pdf/2310.10996.pdf) (10/2023)
    - [Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation](https://arxiv.org/pdf/2310.10698.pdf) (10/2023)
- Logical reasoning
  - 2023
    - [Language Models can be Logical Solvers](https://arxiv.org/pdf/2311.06158.pdf)
- Math  
  - 2024
    - [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300.pdf)
- Meta
  - 2023
    - [MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation](https://arxiv.org/pdf/2312.17080.pdf) (12/2023)
    - [Metacognitive Prompting Improves Understanding in Large Language Models](https://arxiv.org/pdf/2308.05342.pdf) (08/2023)
    - [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://arxiv.org/pdf/2306.17820.pdf) (06/2023)

## Context window

> Papers in this section address how expanding the contextual awareness of models can significantly enhance memory and attention mechanisms. This includes exploring architectures that handle long-term dependencies and infinite contexts to improve the working memory of transformers.

- Extension
  - 2024
    - [TransformerFAM: Feedback attention is working memory](https://arxiv.org/pdf/2404.09173.pdf) (04/2024)
    - [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/pdf/2404.07143.pdf) (04/2024)
    - [InfLLM: Unveiling the Intrinsic Capacity of LLMs for Understanding Extremely Long Sequences](https://arxiv.org/pdf/2402.04617.pdf) (02/2024)
    - [LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens](https://arxiv.org/abs/2402.13753) (02/2024)
    - [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning](https://arxiv.org/abs/2401.01325) (01/2024)

## Operational efficiency

> Focuses on optimizing the computational efficiency and practical deployment of LLMs. This includes reducing the computational load, increasing inference speed, improving resource allocation, and strategies to minimize costs without sacrificing performance.

- 2024
  - [ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference](https://arxiv.org/pdf/2404.07947.pdf) (04/2024)
  - [FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping](https://arxiv.org/pdf/2404.03865.pdf) (04/2024)
  - [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/pdf/2404.02258.pdf) (04/2024)
  - [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764.pdf) (02/2024)
- 2023
  - [Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy](https://arxiv.org/pdf/2312.12728.pdf) (12/2023)
  - [Exponential Faster Language Models](https://arxiv.org/pdf/2311.10770.pdf) (11/2023)
  - [Efficient LLM Inference on CPUs](https://arxiv.org/pdf/2311.00502.pdf) (11/2023)
  - [Cache me if you Can: an Online Cost-aware Teacher-Student Framework to Reduce the Calls to Large Language Models](https://arxiv.org/pdf/2310.13395.pdf) (10/2023)
  - [Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer](https://arxiv.org/pdf/2310.19902.pdf) (10/2023)
  - [SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills](https://arxiv.org/pdf/2308.16369.pdf) (08/2023)
  - [EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models](https://arxiv.org/pdf/2308.14352.pdf) (08/2023)
  - [FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance](https://arxiv.org/pdf/2305.05176.pdf) (05/2023)
  - [Paper page - LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://huggingface.co/papers/2312.11514) (12/2023)
  - [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://tridao.me/publications/flash2/flash2.pdf)

## Hallucination/Factuality

> This segment covers research on minimizing hallucinations—false or misleading information generated by LLMs. Papers propose various techniques for enhancing the fact-checking capabilities of models, ensuring more reliable and factual outputs.

- 2023
  - [CHAIN-OF-VERIFICATION REDUCES HALLUCINATION IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2309.11495.pdf) (09/2023)
  - [Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection](https://arxiv.org/pdf/2310.12086.pdf) (10/2023)
  - [Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models](https://arxiv.org/pdf/2305.14623.pdf) (05/2023)
  - [“Oops, Did I Just Say That?” Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process](https://arxiv.org/pdf/2305.02626.pdf) (05/2023)
  - [SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://arxiv.org/pdf/2303.08896.pdf) (03/2023)


## Specific niche/topics

> Includes papers that apply LLMs to specialized fields such as data science, DevOps, and personalized learning. These studies explore how LLMs can be tailored to specific professional tasks, including automated code generation and data interpretation.

- Data Science
  - 2024
    - [DS-Agent: Automated Data Science by Empowering Large Language Models with Case-Based Reasoning](https://arxiv.org/pdf/2402.17453.pdf) (04/2024)
    - [DATA INTERPRETER: AN LLM AGENT FOR DATA SCIENCE](https://arxiv.org/pdf/2402.18679.pdf)
- Coding (and related)
  - 2023
    - [Automated DevOps Pipeline Generation for Code Repositories using Large Language Models](https://arxiv.org/pdf/2312.13225.pdf) (12/2023)
    - [Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation](https://arxiv.org/pdf/2310.18628.pdf) (10/2023)
    - [Static Code Analysis in the AI Era: An In-depth Exploration of the Concept, Function, and Potential of Intelligent Code Analysis Agents](https://arxiv.org/pdf/2310.08837.pdf) (10/2023)
    - [Private-Library-Oriented Code Generation with Large Language Models](https://arxiv.org/pdf/2307.15370.pdf) (07/2023)
    - [Exploring the Robustness of Large Language Models for Solving Programming Problems](https://arxiv.org/pdf/2306.14583.pdf) (06/2023)
    - [Self-collaboration Code Generation via ChatGPT](https://arxiv.org/pdf/2304.07590.pdf) (04/2023)
    - [Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study](https://arxiv.org/pdf/2304.07575.pdf) (04/2023)

## Evaluation/benchmarking

> This section presents methodologies for assessing the performance of LLMs, particularly in handling extensive contexts and complex reasoning tasks. It includes innovative evaluation strategies that aim to provide more comprehensive and practical assessments of model capabilities.

- 2024
  - [Counting-Stars (★): A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models](https://arxiv.org/pdf/2403.11802.pdf)

## Training

> Discusses methods and strategies for the continuous training and improvement of LLMs. Topics include token efficiency, scalable training strategies, and data autonomy to enhance the learning process without extensive resources.

- General
  - 2024
    - [RHO-1: Not All Tokens Are What You Need](https://arxiv.org/pdf/2404.07965.pdf) (04/2024)
    - [ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy](https://arxiv.org/pdf/2403.14589.pdf) (03/2024)
    - [Rephrasing the Web (from Apple)](https://arxiv.org/pdf/2401.16380.pdf) (01/2024)
  - 2023
    - [Agent LUMOS: Unified and Modular Training for Open-Source Language Agents](https://arxiv.org/pdf/2311.05657.pdf) (11/2023)

- "Continuous" learning
  - 2024
    - [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/pdf/2403.08763.pdf)
    - [Larimar: Large Language Models with Episodic Memory Control](https://arxiv.org/pdf/2403.11901.pdf)

## Tools/tool use

> Explores how LLMs can be integrated with external tools or APIs to extend their functionality beyond pure text processing. This includes learning to interact with and manipulate external software tools or databases, thereby broadening the practical applications of LLMs.

- 2023
  - [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/pdf/2305.15334.pdf) (05/2023)
  - [GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution](https://arxiv.org/pdf/2307.08775.pdf) (07/2023)
  - [Tool Learning with Foundation Models](https://arxiv.org/pdf/2304.08354.pdf) (04/2023)


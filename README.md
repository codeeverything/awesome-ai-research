# Welcome to Awesome AI Research

> NB: This repo is a WIP and I hope to keep refreshing and extending it as time allows

Welcome to `awesome-ai-research`, a personal collection of research papers that have piqued my interest in the expansive field of artificial intelligence, especially focusing on Large Language Models (LLMs) and their multifaceted applications.

Artificial intelligence is a dynamic field where innovation is constant. The papers included here reflect a range of work that I've found interesting - you may or may not too! :)

Here, you'll discover papers covering everything from enhancing the reasoning abilities of AI systems to innovative approaches for training and benchmarking. Each selection is driven by a personal interest and a belief in the importance of the work, rather than a comprehensive or systematic review.

I hope this collection serves as a springboard for your exploration and inspires a deeper understanding and appreciation of artificial intelligence.

## Reasoning

> This section presents papers exploring advanced reasoning capabilities of Large Language Models (LLMs). Topics include self-improvement techniques, multi-agent systems, ethical reasoning, mathematical reasoning, and approaches to enhance LLMs' ability to process and generate logically coherent and contextually relevant responses. Expect insights on enhancing code generation, debugging, and solving complex algorithmic challenges.

1. [Stream of Search (SoS): Learning to Search in Language](https://arxiv.org/pdf/2404.03683.pdf)
2. [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](https://arxiv.org/pdf/2404.02575.pdf)
3. [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing (AlphaLLM)](https://arxiv.org/pdf/2404.12253.pdf)
4. [DON’T TRUST: VERIFY – GROUNDING LLM QUANTITATIVE REASONING WITH AUTOFORMALIZATION](https://arxiv.org/pdf/2403.18120.pdf)
5. [MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue ReSolution](https://arxiv.org/pdf/2403.17927.pdf)
6. [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/pdf/2403.09629.pdf)
7. [Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering](https://arxiv.org/pdf/2401.08500.pdf)
8. [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://arxiv.org/pdf/2402.03300.pdf)
9. [Self-Discover: Large Language Models Self-Compose Reasoning Structures](https://arxiv.org/pdf/2402.03620.pdf)
10. [BRANCH-SOLVE-MERGE IMPROVES LARGE LANGUAGE MODEL EVALUATION AND GENERATION](https://arxiv.org/pdf/2310.15123.pdf)
11. [MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning](https://arxiv.org/pdf/2311.02303.pdf)
12. [HINT-ENHANCED IN-CONTEXT LEARNING WAKES LARGE LANGUAGE MODELS UP FOR KNOWLEDGE-INTENSIVE TASKS](https://arxiv.org/pdf/2311.01949.pdf)
13. [Language Models can be Logical Solvers](https://arxiv.org/pdf/2311.06158.pdf)
14. [COFFEE: Boost Your Code LLMs by Fixing Bugs with Feedback](https://arxiv.org/pdf/2311.07215.pdf)
15. [INTERVENOR : Prompting the Coding Ability of Large Language Models with the Interactive Chain of Repair](https://arxiv.org/pdf/2311.09868.pdf)
16. [Retrieval-Augmented Multi-Modal Chain-of-Thoughts Reasoning for Large Language Models](https://arxiv.org/pdf/2312.01714.pdf)
17. [AgentCoder: Multiagent-Code Generation with Iterative Testing and Optimisation](https://arxiv.org/pdf/2312.13010.pdf)
18. [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models](https://arxiv.org/pdf/2312.17080.pdf)
19. [MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation](https://arxiv.org/pdf/2312.17080.pdf)
20. [Metacognitive Prompting Improves Understanding in Large Language Models](https://arxiv.org/pdf/2308.05342.pdf)
21. [Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation](https://arxiv.org/pdf/2310.10698.pdf)
22. [ClarifyGPT: Empowering LLM-based Code Generation with Intention Clarification](https://arxiv.org/pdf/2310.10996.pdf)
23. [LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers](https://arxiv.org/pdf/2310.15164.pdf)
24. [Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models](https://arxiv.org/pdf/2304.09842.pdf)
25. [Progressive-Hint Prompting Improves Reasoning in Large Language Models](https://arxiv.org/pdf/2304.09797.pdf)
26. [Causal Reasoning and Large Language Models: Opening a New Frontier for Causality](https://arxiv.org/pdf/2305.00050.pdf)
27. [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://arxiv.org/pdf/2305.04091.pdf)
28. [Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework](https://arxiv.org/pdf/2305.03268.pdf)
29. [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/pdf/2305.10601.pdf)
30. [Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context Reasoning with Language Models](https://arxiv.org/pdf/2306.06891.pdf)
31. [Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language Models](https://arxiv.org/pdf/2306.17820.pdf)
32. [Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models](https://arxiv.org/pdf/2309.05605.pdf)
33. [MAMMOTH: BUILDING MATH GENERALIST MODELS THROUGH HYBRID INSTRUCTION TUNING](https://arxiv.org/pdf/2309.05653.pdf)

## Context window

> Papers in this section address how expanding the contextual awareness of models can significantly enhance memory and attention mechanisms. This includes exploring architectures that handle long-term dependencies and infinite contexts to improve the working memory of transformers.

1. [TransformerFAM: Feedback attention is working memory](https://arxiv.org/pdf/2404.09173.pdf)
2. [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](https://arxiv.org/pdf/2404.07143.pdf)

## Operational efficiency

> Focuses on optimizing the computational efficiency and practical deployment of LLMs. This includes reducing the computational load, increasing inference speed, improving resource allocation, and strategies to minimize costs without sacrificing performance.

1. [ExeGPT: Constraint-Aware Resource Scheduling for LLM Inference](https://arxiv.org/pdf/2404.07947.pdf)
2. [FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping](https://arxiv.org/pdf/2404.03865.pdf)
3. [Mixture-of-Depths: Dynamically allocating compute in transformer-based language models](https://arxiv.org/pdf/2404.02258.pdf)
4. [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764.pdf)
5. [Herd: Using multiple, smaller LLMs to match the performances of proprietary, large LLMs via an intelligent composer](https://arxiv.org/pdf/2310.19902.pdf)
6. [Efficient LLM Inference on CPUs](https://arxiv.org/pdf/2311.00502.pdf)
7. [Lookahead: An Inference Acceleration Framework for Large Language Model with Lossless Generation Accuracy](https://arxiv.org/pdf/2312.12728.pdf)
8. [Cache me if you Can: an Online Cost-aware Teacher-Student Framework to Reduce the Calls to Large Language Models](https://arxiv.org/pdf/2310.13395.pdf)
9. [FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance](https://arxiv.org/pdf/2305.05176.pdf)
10. [SARATHI: Efficient LLM Inference by Piggybacking Decodes with Chunked Prefills](https://arxiv.org/pdf/2308.16369.pdf)
11. [EdgeMoE: Fast On-Device Inference of MoE-based Large Language Models](https://arxiv.org/pdf/2308.14352.pdf)
12. [FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning](https://tridao.me/publications/flash2/flash2.pdf)
13. [Paper page - LLM in a flash: Efficient Large Language Model Inference with Limited Memory](https://huggingface.co/papers/2312.11514)

## Hallucination/Factuality

> This segment covers research on minimizing hallucinations—false or misleading information generated by LLMs. Papers propose various techniques for enhancing the fact-checking capabilities of models, ensuring more reliable and factual outputs.

1. [Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models](https://arxiv.org/pdf/2305.14623.pdf)
2. [CHAIN-OF-VERIFICATION REDUCES HALLUCINATION IN LARGE LANGUAGE MODELS](https://arxiv.org/pdf/2309.11495.pdf)
3. [Unveiling the Siren's Song: Towards Reliable Fact-Conflicting Hallucination Detection](https://arxiv.org/pdf/2310.12086.pdf)
4. [“Oops, Did I Just Say That?” Testing and Repairing Unethical Suggestions of Large Language Models with Suggest-Critique-Reflect Process](https://arxiv.org/pdf/2305.02626.pdf)
5. [SELFCHECKGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models](https://arxiv.org/pdf/2303.08896.pdf)

## Specific niche/topics

> Includes papers that apply LLMs to specialized fields such as data science, DevOps, and personalized learning. These studies explore how LLMs can be tailored to specific professional tasks, including automated code generation and data interpretation.

1. [DATA INTERPRETER: AN LLM AGENT FOR DATA SCIENCE](https://arxiv.org/pdf/2402.18679.pdf)
2. [Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation](https://arxiv.org/pdf/2310.18628.pdf)
3. [Automated DevOps Pipeline Generation for Code Repositories using Large Language Models](https://arxiv.org/pdf/2312.13225.pdf)
4. [Static Code Analysis in the AI Era: An In-depth Exploration of the Concept, Function, and Potential of Intelligent Code Analysis Agents](https://arxiv.org/pdf/2310.08837.pdf)
5. [Self-collaboration Code Generation via ChatGPT](https://arxiv.org/pdf/2304.07590.pdf)
6. [Constructing Effective In-Context Demonstration for Code Intelligence Tasks: An Empirical Study](https://arxiv.org/pdf/2304.07575.pdf)
7. [Exploring the Robustness of Large Language Models for Solving Programming Problems](https://arxiv.org/pdf/2306.14583.pdf)
8. [Private-Library-Oriented Code Generation with Large Language Models](https://arxiv.org/pdf/2307.15370.pdf)

## Evaluation/benchmarking

> This section presents methodologies for assessing the performance of LLMs, particularly in handling extensive contexts and complex reasoning tasks. It includes innovative evaluation strategies that aim to provide more comprehensive and practical assessments of model capabilities.

1. [Counting-Stars (★): A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models](https://arxiv.org/pdf/2403.11802.pdf)

## Training

> Discusses methods and strategies for the continuous training and improvement of LLMs. Topics include token efficiency, scalable training strategies, and data autonomy to enhance the learning process without extensive resources.

1. [RHO-1: Not All Tokens Are What You Need](https://arxiv.org/pdf/2404.07965.pdf)
2. [Simple and Scalable Strategies to Continually Pre-train Large Language Models](https://arxiv.org/pdf/2403.08763.pdf)
3. [ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy](https://arxiv.org/pdf/2403.14589.pdf)
4. [Agent LUMOS: Unified and Modular Training for Open-Source Language Agents](https://arxiv.org/pdf/2311.05657.pdf)

## Tools/tool use

> Explores how LLMs can be integrated with external tools or APIs to extend their functionality beyond pure text processing. This includes learning to interact with and manipulate external software tools or databases, thereby broadening the practical applications of LLMs.

1. [GEAR: Augmenting Language Models with Generalizable and Efficient Tool Resolution](https://arxiv.org/pdf/2307.08775.pdf)
2. [Tool Learning with Foundation Models](https://arxiv.org/pdf/2304.08354.pdf)
3. [Gorilla: Large Language Model Connected with Massive APIs](https://arxiv.org/pdf/2305.15334.pdf)
